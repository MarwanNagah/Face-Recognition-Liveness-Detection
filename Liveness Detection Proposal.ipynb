{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('imagesDataset.csv') as csvfile:\n",
    "#     pathsArray=[]\n",
    "#     labelsArray=[]\n",
    "#     readCSV = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in readCSV:\n",
    "#         pathsArray.append(row[0])\n",
    "#         labelsArray.append(row[1])\n",
    "# print (pathsArray)\n",
    "#################################\n",
    "# image = load_img(pathsArray[10])\n",
    "# plt.imshow(image)\n",
    "#################################\n",
    "# def image_processing(image_path):\n",
    "#     img = cv2.imread(image_path,0)\n",
    "#     image = np.asarray(bytearray(img.read()), dtype=\"uint8\")\n",
    "#     image_bgr = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "#     image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "#     image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "#     mask = cv2.inRange(image_hsv, (0,255,255), (0,255,255))\n",
    "# image_processing('CelebA_Spoof\\\\Data\\\\train\\\\98\\\\live\\\\286606.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1052 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-3-0ed6dd56b044>:62: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 60s 924ms/step - loss: 0.6071 - accuracy: 0.7307 - val_loss: 0.5739 - val_accuracy: 0.6823\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 0.3433 - accuracy: 0.8523 - val_loss: 0.6951 - val_accuracy: 0.6042\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 0.2671 - accuracy: 0.8697 - val_loss: 0.8051 - val_accuracy: 0.6823\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.2349 - accuracy: 0.9102 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 0.2157 - accuracy: 0.9102 - val_loss: 0.4283 - val_accuracy: 0.8229\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 54s 836ms/step - loss: 0.2125 - accuracy: 0.9151 - val_loss: 0.3253 - val_accuracy: 0.8958\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 0.1937 - accuracy: 0.9276 - val_loss: 0.3800 - val_accuracy: 0.8385\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 0.1844 - accuracy: 0.9324 - val_loss: 2.2413 - val_accuracy: 0.5781\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 0.1830 - accuracy: 0.9344 - val_loss: 0.5171 - val_accuracy: 0.8229\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 0.1671 - accuracy: 0.9431 - val_loss: 0.2374 - val_accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'CelebA_Spoof/Data/train'\n",
    "validation_data_dir = 'CelebA_Spoof/Data/test'\n",
    "nb_train_samples = 1052\n",
    "nb_validation_samples = 200\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
