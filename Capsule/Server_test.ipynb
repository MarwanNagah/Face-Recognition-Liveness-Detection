{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify,request\n",
    "import webbrowser\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD #1: OpenCV, NumPy, and urllib\n",
    "def url_to_image(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    name = \"sample_image.jpg\"\n",
    "\n",
    "    file = open(name, \"wb\")\n",
    "    file.write(response.content)\n",
    "    file.close()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(path,cv2.IMREAD_COLOR) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    img_width, img_height, img_num_channels = 50, 50, 3\n",
    "    ops.reset_default_graph()\n",
    "    X = tf.placeholder(shape=[None, 50, 50, 3], dtype=tf.float32, name=\"X\")\n",
    "    caps1_n_maps = 32\n",
    "    caps1_n_caps = caps1_n_maps * 17 * 17  # 1152 primary capsules\n",
    "    caps1_n_dims = 8\n",
    "    conv1_params = {\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 9,\n",
    "        \"strides\": 1,\n",
    "        \"padding\": \"valid\",\n",
    "        \"activation\": tf.nn.relu,\n",
    "    }\n",
    "\n",
    "    conv2_params = {\n",
    "        \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "        \"kernel_size\": 9,\n",
    "        \"strides\": 2,\n",
    "        \"padding\": \"valid\",\n",
    "        \"activation\": tf.nn.relu\n",
    "    }\n",
    "    conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "    conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "    caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                           name=\"caps1_raw\")\n",
    "    def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "        with tf.name_scope(name, default_name=\"squash\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keep_dims=True)\n",
    "            safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "            squash_factor = squared_norm / (1. + squared_norm)\n",
    "            unit_vector = s / safe_norm\n",
    "            return squash_factor * unit_vector\n",
    "    caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "    caps2_n_caps = 10\n",
    "    caps2_n_dims = 16\n",
    "    init_sigma = 0.1\n",
    "\n",
    "    W_init = tf.random_normal(\n",
    "        shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "        stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "    W = tf.Variable(W_init, name=\"W\")\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "    caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                           name=\"caps1_output_expanded\")\n",
    "    caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                       name=\"caps1_output_tile\")\n",
    "    caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                                 name=\"caps1_output_tiled\")\n",
    "    caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                                name=\"caps2_predicted\")\n",
    "    raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                           dtype=np.float32, name=\"raw_weights\")\n",
    "    routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "    weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                       name=\"weighted_predictions\")\n",
    "    weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                                 name=\"weighted_sum\")\n",
    "    caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                                  name=\"caps2_output_round_1\")\n",
    "    caps2_output_round_1_tiled = tf.tile(\n",
    "        caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "        name=\"caps2_output_round_1_tiled\")\n",
    "    agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                          transpose_a=True, name=\"agreement\")\n",
    "    raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                                 name=\"raw_weights_round_2\")\n",
    "    routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                            dim=2,\n",
    "                                            name=\"routing_weights_round_2\")\n",
    "    weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                               caps2_predicted,\n",
    "                                               name=\"weighted_predictions_round_2\")\n",
    "    weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                         axis=1, keep_dims=True,\n",
    "                                         name=\"weighted_sum_round_2\")\n",
    "    caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                                  axis=-2,\n",
    "                                  name=\"caps2_output_round_2\")\n",
    "    caps2_output = caps2_output_round_2\n",
    "    def condition(input, counter):\n",
    "        return tf.less(counter, 100)\n",
    "\n",
    "    def loop_body(input, counter):\n",
    "        output = tf.add(input, tf.square(counter))\n",
    "        return output, tf.add(counter, 1)\n",
    "\n",
    "    with tf.name_scope(\"compute_sum_of_squares\"):\n",
    "        counter = tf.constant(1)\n",
    "        sum_of_squares = tf.constant(0)\n",
    "\n",
    "        result = tf.while_loop(condition, loop_body, [sum_of_squares, counter])\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(result))\n",
    "    def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "        with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keep_dims=keep_dims)\n",
    "            return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "    y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "    y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "    y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "    y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "    m_plus = 0.9\n",
    "    m_minus = 0.1\n",
    "    lambda_ = 0.5\n",
    "    T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "    with tf.Session():\n",
    "        print(T.eval(feed_dict={y: np.array([0, 1, 2, 3, 9])}))\n",
    "    caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                                  name=\"caps2_output_norm\")\n",
    "    present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                                  name=\"present_error_raw\")\n",
    "    present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
    "                               name=\"present_error\")\n",
    "    absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                                 name=\"absent_error_raw\")\n",
    "    absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
    "                              name=\"absent_error\")\n",
    "    L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "               name=\"L\")\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "    mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                                   name=\"mask_with_labels\")\n",
    "    reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                     lambda: y,        # if True\n",
    "                                     lambda: y_pred,   # if False\n",
    "                                     name=\"reconstruction_targets\")\n",
    "    reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                     depth=caps2_n_caps,\n",
    "                                     name=\"reconstruction_mask\")\n",
    "    reconstruction_mask_reshaped = tf.reshape(\n",
    "        reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "        name=\"reconstruction_mask_reshaped\")\n",
    "    caps2_output_masked = tf.multiply(\n",
    "        caps2_output, reconstruction_mask_reshaped,\n",
    "        name=\"caps2_output_masked\")\n",
    "    decoder_input = tf.reshape(caps2_output_masked,\n",
    "                               [-1, caps2_n_caps * caps2_n_dims],\n",
    "                               name=\"decoder_input\")\n",
    "\n",
    "    n_hidden1 = 512\n",
    "    n_hidden2 = 1024\n",
    "    n_output = 50 * 50 * 3\n",
    "\n",
    "    with tf.name_scope(\"decoder\"):\n",
    "        hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                                  activation=tf.nn.relu,\n",
    "                                  name=\"hidden1\")\n",
    "        hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                                  activation=tf.nn.relu,\n",
    "                                  name=\"hidden2\")\n",
    "        decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                         activation=tf.nn.sigmoid,\n",
    "                                         name=\"decoder_output\")\n",
    "    X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "    squared_difference = tf.square(X_flat - decoder_output,\n",
    "                                   name=\"squared_difference\")\n",
    "    reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                        name=\"reconstruction_loss\")\n",
    "    alpha = 0.0005\n",
    "\n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "    correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    imagesArrayTest = np.zeros((1,img_width,img_height,img_num_channels),dtype = 'float32')\n",
    "    \n",
    "    img = cv2.imread(\"sample_image.jpg\")\n",
    "    img = cv2.resize(img,(img_width,img_height))\n",
    "    imagesArrayTest[0]= img\n",
    "    cv2.imwrite(\"Sample_image1.jpg\",img)\n",
    "\n",
    "    config = tf.ConfigProto(\n",
    "            device_count = {'GPU': 0}\n",
    "        )\n",
    "\n",
    "    n_samples = 1\n",
    "    sample_images = imagesArrayTest[:n_samples].reshape([-1, 50, 50, 3])\n",
    "    sample_images = sample_images/255\n",
    "    \n",
    "    checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "                [caps2_output, decoder_output, y_pred],\n",
    "                feed_dict={X: sample_images,\n",
    "                           y: np.array([], dtype=np.int64)})\n",
    "    sample_images = sample_images.reshape(-1, 50, 50,3)\n",
    "    reconstructions = decoder_output_value.reshape([-1, 50, 50,3])\n",
    "\n",
    "    plt.figure(figsize=(n_samples * 2, 3))\n",
    "    for index in range(n_samples):\n",
    "        plt.subplot(1, n_samples, index + 1)\n",
    "        plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "        plt.title(\"Label:\" + str(0))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(n_samples * 2, 3))\n",
    "    for index in range(n_samples):\n",
    "        plt.subplot(1, n_samples, index + 1)\n",
    "        plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "        plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred_value[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_images = sample_images.reshape(-1, 50, 50,3)\n",
    "# reconstructions = decoder_output_value.reshape([-1, 50, 50,3])\n",
    "\n",
    "# plt.figure(figsize=(n_samples * 2, 3))\n",
    "# for index in range(n_samples):\n",
    "#     plt.subplot(1, n_samples, index + 1)\n",
    "#     plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "#     plt.title(\"Label:\" + str(X_test[index]))\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(n_samples * 2, 3))\n",
    "# for index in range(n_samples):\n",
    "#     plt.subplot(1, n_samples, index + 1)\n",
    "#     plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "#     plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/api',methods=['GET'])\n",
    "def main_def():\n",
    "    url = 'https://firebasestorage.googleapis.com/v0/b/face-liveness-detection-bca56.appspot.com/o/Face_Images%2F'\n",
    "    d = {}\n",
    "    #json_file = {}\n",
    "    #result='afsha'\n",
    "    #json_file['query'] = result\n",
    "    d['path'] = str(request.args['path'])\n",
    "    d['token'] = str(request.args['token'])\n",
    "    url=url+d['path']+'%7D?alt=media&token='+d['token']+'.jpg'\n",
    "    pathImage = url_to_image(url)\n",
    "    imageData =read_image(pathImage)\n",
    "    d['result'] = str(classify(imageData))\n",
    "    return jsonify(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
