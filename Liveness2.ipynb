{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1052 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "65/65 [==============================] - 48s 744ms/step - loss: 0.6250 - accuracy: 0.7181 - val_loss: 0.5298 - val_accuracy: 0.7135\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 0.3904 - accuracy: 0.8475 - val_loss: 0.6683 - val_accuracy: 0.6354\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 0.3145 - accuracy: 0.8803 - val_loss: 0.4886 - val_accuracy: 0.7083\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 0.2732 - accuracy: 0.8986 - val_loss: 0.5149 - val_accuracy: 0.7188\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 0.2719 - accuracy: 0.8929 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 0.2857 - accuracy: 0.9035 - val_loss: 0.8322 - val_accuracy: 0.7240\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 0.2182 - accuracy: 0.9180 - val_loss: 0.4209 - val_accuracy: 0.8177\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 0.2147 - accuracy: 0.9257 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 48s 739ms/step - loss: 0.1769 - accuracy: 0.9305 - val_loss: 0.8164 - val_accuracy: 0.7760\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 0.1790 - accuracy: 0.9218 - val_loss: 1.6132 - val_accuracy: 0.7240\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 0.2137 - accuracy: 0.9344 - val_loss: 0.6978 - val_accuracy: 0.8177\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 50s 772ms/step - loss: 0.1594 - accuracy: 0.9382 - val_loss: 0.3129 - val_accuracy: 0.8750\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 48s 739ms/step - loss: 0.1507 - accuracy: 0.9517 - val_loss: 0.4231 - val_accuracy: 0.8229\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 0.1588 - accuracy: 0.9498 - val_loss: 0.4220 - val_accuracy: 0.7865\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 49s 752ms/step - loss: 0.1803 - accuracy: 0.9382 - val_loss: 0.5564 - val_accuracy: 0.8385\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 47s 727ms/step - loss: 0.1545 - accuracy: 0.9469 - val_loss: 0.3593 - val_accuracy: 0.8438\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 50s 768ms/step - loss: 0.1318 - accuracy: 0.9595 - val_loss: 0.4190 - val_accuracy: 0.8542\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 50s 764ms/step - loss: 0.1864 - accuracy: 0.9440 - val_loss: 0.5869 - val_accuracy: 0.8073\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 53s 810ms/step - loss: 0.1596 - accuracy: 0.9488 - val_loss: 0.6773 - val_accuracy: 0.8385\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 0.1244 - accuracy: 0.9508 - val_loss: 0.3664 - val_accuracy: 0.8490\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 0.1379 - accuracy: 0.9546 - val_loss: 0.9834 - val_accuracy: 0.8542\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 0.1475 - accuracy: 0.9643 - val_loss: 0.5982 - val_accuracy: 0.8594\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 0.1224 - accuracy: 0.9575 - val_loss: 0.4777 - val_accuracy: 0.8594\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 0.1279 - accuracy: 0.9585 - val_loss: 0.4429 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 48s 737ms/step - loss: 0.2166 - accuracy: 0.9527 - val_loss: 0.3891 - val_accuracy: 0.8698\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.1064 - accuracy: 0.9643 - val_loss: 1.7782 - val_accuracy: 0.7865\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 48s 746ms/step - loss: 0.1533 - accuracy: 0.9566 - val_loss: 0.4014 - val_accuracy: 0.8385\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 0.1067 - accuracy: 0.9662 - val_loss: 0.6325 - val_accuracy: 0.8385\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 0.1478 - accuracy: 0.9662 - val_loss: 0.3836 - val_accuracy: 0.8490\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 48s 733ms/step - loss: 0.1567 - accuracy: 0.9604 - val_loss: 1.7948 - val_accuracy: 0.7188\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 0.1144 - accuracy: 0.9672 - val_loss: 1.3092 - val_accuracy: 0.8177\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 0.1213 - accuracy: 0.9517 - val_loss: 1.1236 - val_accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 0.1761 - accuracy: 0.9633 - val_loss: 0.7429 - val_accuracy: 0.8438\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 0.1251 - accuracy: 0.9624 - val_loss: 0.7041 - val_accuracy: 0.8490\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 1.5000 - val_accuracy: 0.8490\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 49s 760ms/step - loss: 0.0991 - accuracy: 0.9653 - val_loss: 6.8050 - val_accuracy: 0.6927\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 0.1057 - accuracy: 0.9691 - val_loss: 0.8306 - val_accuracy: 0.8802\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 0.0989 - accuracy: 0.9749 - val_loss: 1.8376 - val_accuracy: 0.8281\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 49s 756ms/step - loss: 0.0941 - accuracy: 0.9710 - val_loss: 0.7984 - val_accuracy: 0.8802\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.1153 - accuracy: 0.9710 - val_loss: 1.2874 - val_accuracy: 0.8542\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 49s 749ms/step - loss: 0.1539 - accuracy: 0.9672 - val_loss: 0.5108 - val_accuracy: 0.8906\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 0.1002 - accuracy: 0.9701 - val_loss: 1.0297 - val_accuracy: 0.8906\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 0.1204 - accuracy: 0.9710 - val_loss: 0.5741 - val_accuracy: 0.8646\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 0.0845 - accuracy: 0.9730 - val_loss: 1.8558 - val_accuracy: 0.8594\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 0.1261 - accuracy: 0.9653 - val_loss: 1.6058 - val_accuracy: 0.8594\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 0.2230 - accuracy: 0.9720 - val_loss: 0.5590 - val_accuracy: 0.8958\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 0.0757 - accuracy: 0.9749 - val_loss: 1.7162 - val_accuracy: 0.8542\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 0.0816 - accuracy: 0.9817 - val_loss: 0.9663 - val_accuracy: 0.8490\n",
      "Epoch 49/50\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 0.1633 - accuracy: 0.9614 - val_loss: 0.7574 - val_accuracy: 0.8438\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.0575 - accuracy: 0.9768 - val_loss: 1.5639 - val_accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'CelebA_Spoof/Data/train'\n",
    "validation_data_dir = 'CelebA_Spoof/Data/test'\n",
    "nb_train_samples = 1052\n",
    "nb_validation_samples = 200\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-131a37b1e3e4>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5013763904571533, 0.8700000047683716]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(\n",
    "  validation_generator,\n",
    "  nb_validation_samples/batch_size,\n",
    "  workers = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
